{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0c9f46",
   "metadata": {},
   "source": [
    "# Melanoma Classification using CNN\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) for melanoma detection using processed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1893f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c035d9c",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "We'll load the processed images for melanoma classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "base_path = '../'\n",
    "processed_dir = os.path.join(base_path, 'working', 'processed_images')\n",
    "melanoma_dir = os.path.join(processed_dir, 'melanoma')\n",
    "non_melanoma_dir = os.path.join(processed_dir, 'non_melanoma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7db491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from directories\n",
    "def load_images_from_directory(directory, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Warning: Directory {directory} does not exist!\")\n",
    "        return images, labels\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (224, 224))  # Ensure consistent size\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load melanoma and non-melanoma images\n",
    "print(\"Loading melanoma images...\")\n",
    "melanoma_images, melanoma_labels = load_images_from_directory(melanoma_dir, 1)\n",
    "\n",
    "print(\"Loading non-melanoma images...\")\n",
    "non_melanoma_images, non_melanoma_labels = load_images_from_directory(\n",
    "    non_melanoma_dir, 0)\n",
    "\n",
    "# Combine datasets\n",
    "X = np.array(melanoma_images + non_melanoma_images)\n",
    "y = np.array(melanoma_labels + non_melanoma_labels)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset loaded: {X.shape[0]} images\")\n",
    "print(f\"Melanoma images: {len(melanoma_images)}\")\n",
    "print(f\"Non-melanoma images: {len(non_melanoma_images)}\")\n",
    "\n",
    "# Technically this should be done in data augmentation and pre-processing but for now we are lazy\n",
    "# Reshape and normalize images for CNN input\n",
    "X = X.reshape(-1, 224, 224, 1).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983500bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Balancing the data set with the same number of melanoma samples since we'll augment them\n",
    "target_samples = 8000\n",
    "\n",
    "print(f\"Original dataset - Melanoma: {len(melanoma_images)}, Non-melanoma: {len(non_melanoma_images)}\")\n",
    "\n",
    "# 1. Subsample non-melanoma images to reduce class imbalance\n",
    "non_melanoma_indices = list(range(len(non_melanoma_images)))\n",
    "random.seed(42)\n",
    "random.shuffle(non_melanoma_indices)\n",
    "non_melanoma_indices = non_melanoma_indices[:target_samples]\n",
    "non_melanoma_images_balanced = [non_melanoma_images[i] for i in non_melanoma_indices]\n",
    "non_melanoma_labels_balanced = [non_melanoma_labels[i] for i in non_melanoma_indices]\n",
    "\n",
    "print(f\"After subsampling - Non-melanoma: {len(non_melanoma_images_balanced)}\")\n",
    "\n",
    "# 2. Create augmentation pipeline\n",
    "augmentation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "    A.GridDistortion(p=0.3),\n",
    "    A.ElasticTransform(p=0.3),\n",
    "])\n",
    "\n",
    "melanoma_images_augmented = melanoma_images.copy()\n",
    "melanoma_labels_augmented = melanoma_labels.copy()\n",
    "\n",
    "print(\"Augmenting melanoma images...\")\n",
    "\n",
    "# Generate augmented images for the melanoma class to balance dataset\n",
    "num_augmentations_needed = target_samples - len(melanoma_images)\n",
    "images_to_augment = random.choices(melanoma_images, k=num_augmentations_needed)\n",
    "\n",
    "for img in images_to_augment:\n",
    "    img_uint8 = img.astype(np.uint8)\n",
    "    augmented = augmentation(image=img_uint8)\n",
    "    melanoma_images_augmented.append(augmented['image'])\n",
    "    melanoma_labels_augmented.append(1)\n",
    "\n",
    "print(f\"After augmentation - Melanoma: {len(melanoma_images_augmented)}\")\n",
    "\n",
    "# Create balanced dataset\n",
    "X_balanced = np.array(melanoma_images_augmented + non_melanoma_images_balanced)\n",
    "y_balanced = np.array(melanoma_labels_augmented + non_melanoma_labels_balanced)\n",
    "\n",
    "# Shuffle the data\n",
    "X_balanced, y_balanced = shuffle(X_balanced, y_balanced, random_state=42)\n",
    "\n",
    "# Reshape and normalize images for CNN input\n",
    "X_balanced = X_balanced.reshape(-1, 224, 224, 1).astype('float32') / 255.0\n",
    "\n",
    "print(f\"Balanced dataset - Total: {X_balanced.shape[0]} images\")\n",
    "print(f\"Class distribution - Melanoma: {np.sum(y_balanced == 1)}, Non-melanoma: {np.sum(y_balanced == 0)}\")\n",
    "\n",
    "# Replace original X and y with balanced dataset\n",
    "X, y = X_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fed5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets\n",
    "# First split: 80% training+validation, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Second split: 80% training, 20% validation (from the training+validation set)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} images\")\n",
    "print(f\"Validation set: {X_val.shape[0]} images\")\n",
    "print(f\"Test set: {X_test.shape[0]} images\")\n",
    "\n",
    "# Check class distribution in each set\n",
    "print(f\"Training set - Melanoma: {np.sum(y_train == 1)}, Non-melanoma: {np.sum(y_train == 0)}\")\n",
    "print(f\"Validation set - Melanoma: {np.sum(y_val == 1)}, Non-melanoma: {np.sum(y_val == 0)}\")\n",
    "print(f\"Test set - Melanoma: {np.sum(y_test == 1)}, Non-melanoma: {np.sum(y_test == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33031ac2",
   "metadata": {},
   "source": [
    "## 2. Build CNN Model\n",
    "\n",
    "We'll create a CNN model architecture suitable for melanoma classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape=(224, 224, 1)):\n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Second convolutional block\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Third convolutional block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Dense layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_cnn_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('../working/melanoma_model.h5', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: len(y_train[y_train == 0]) / len(y_train[y_train == 1]) if np.sum(y_train == 1) > 0 else 1.0\n",
    "}\n",
    "print(f\"Class weights: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c2688",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab32441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d19492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Melanoma', 'Melanoma']))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9709c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(X, y_true, y_pred, y_pred_proba, num_samples=8):\n",
    "    # Select random samples\n",
    "    indices = np.random.choice(range(len(y_true)), min(num_samples, len(y_true)), replace=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "            \n",
    "        # Get image and labels\n",
    "        img = X[idx].reshape(224, 224)\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "        prob = y_pred_proba[idx][0]\n",
    "        \n",
    "        # Determine text color based on prediction correctness\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        # Plot image\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"True: {'Melanoma' if true_label == 1 else 'Non-Melanoma'}\\n\" +\n",
    "                        f\"Pred: {'Melanoma' if pred_label == 1 else 'Non-Melanoma'} ({prob:.3f})\",\n",
    "                        color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(X_test, y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae68e3",
   "metadata": {},
   "source": [
    "## 4. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ba72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = '../working/melanoma_cnn_final_5.h5'\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Save test results\n",
    "results = {\n",
    "    'accuracy': float(test_acc),\n",
    "    'auc': float(test_auc),\n",
    "    'loss': float(test_loss)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../working/model_results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "print(\"Results saved to ../working/model_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
