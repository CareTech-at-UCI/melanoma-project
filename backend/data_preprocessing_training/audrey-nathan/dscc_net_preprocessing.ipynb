{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03880ef",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Inspired by DSCC_Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465a587",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0bc6b",
   "metadata": {},
   "source": [
    "#### Download ISIC-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519e3ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Base path to ISIC-2019: /Users/audreylu/.cache/kagglehub/datasets/andrewmvd/isic-2019/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "base_path_isic = kagglehub.dataset_download(\"andrewmvd/isic-2019\")\n",
    "print(\"Base path to ISIC-2019:\", base_path_isic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b83978",
   "metadata": {},
   "source": [
    "#### Download HAM10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6040f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/kmader/skin-cancer-mnist-ham10000?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.20G/5.20G [02:30<00:00, 37.0MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path to HAM10000: /Users/audreylu/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "base_path_ham = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
    "print(\"Base path to HAM10000:\", base_path_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce29dc",
   "metadata": {},
   "source": [
    "#### Filter Functions\n",
    "Hair Removal and Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129638c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all_images(input_folder: str, output_folder: str) -> None:\n",
    "    \"\"\"Apply all filtering functions to jpg files in input_folder.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        try:\n",
    "            if file_name.endswith(\".jpg\"):\n",
    "                print(f\"Processing {file_name}...\")\n",
    "                if not os.path.exists(os.path.join(output_folder, file_name)):\n",
    "                    filter_image(input_folder, output_folder, file_name)\n",
    "                else:\n",
    "                    print(f\"{file_name} already exists in {output_folder}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {file_name}: {e}\")\n",
    "\n",
    "def filter_image(input_folder: str, output_folder: str, file_name: str) -> None:\n",
    "    \"\"\"Apply all filtering functions to a single image file.\"\"\"\n",
    "    image_path = os.path.join(input_folder, file_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image from {image_path}\")\n",
    "    else:\n",
    "        image_hr = hair_removal(image)\n",
    "        image_nr = noise_reduction(image_hr)\n",
    "\n",
    "        image_final = image_nr\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        cv2.imwrite(output_path, image_final)\n",
    "\n",
    "def hair_removal(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply hair removal filter to the image using the Dull Razor algorithm.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))  # creates a kernel for morphing\n",
    "    blackhat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)  # apply blackhat filter (highlights dark regions)\n",
    "    bhg = cv2.GaussianBlur(blackhat, (9, 9), cv2.BORDER_REPLICATE)  # smooths image\n",
    "    _, mask = cv2.threshold(bhg, 50, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # creates a binary mask to detect hair-like structure\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    inpainted_image = cv2.inpaint(image_bgr, mask, 4, cv2.INPAINT_TELEA)\n",
    "    return inpainted_image\n",
    "\n",
    "def noise_reduction(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply noise reduction to the image using Median Filtering and Bilateral Filtering.\"\"\"\n",
    "    image_mf = cv2.medianBlur(image, 5)  # Apply median filter to reduce salt and pepper noise\n",
    "    image_bf = cv2.bilateralFilter(image_mf, d=17, sigmaColor=100, sigmaSpace=100)  # Apply bilateral filter to reduce noise while preserving edges\n",
    "    return image_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2ffed",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions\n",
    "SMOTE-Tomek Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_melanoma_images(output_folder: str, data_frame: pd.DataFrame, output_csv_path: str, image_size=(224, 224)) -> None:\n",
    "    \"\"\"\n",
    "    Oversample melanoma images using SMOTE-Tomek.\n",
    "\n",
    "    output_folder: Path to the folder with filtered images and where upsampled images will be saved.\n",
    "    data_frame: DataFrame containing image file names, melanoma (0 or 1), and paths.\n",
    "    output_csv_path: Path to save the updated CSV file.\n",
    "    image_size: Target size (width, height) for resized images.\n",
    "    \"\"\"\n",
    "    # Load melanoma images and their labels\n",
    "    melanoma_df = data_frame[data_frame['melanoma'] == 1]\n",
    "    non_melanoma_df = data_frame[data_frame['melanoma'] == 0]\n",
    "\n",
    "    melanoma_images = []\n",
    "    melanoma_labels = []\n",
    "\n",
    "    for image_path in melanoma_df['path']:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Load as RGB\n",
    "        if image is not None:\n",
    "            resized_image = cv2.resize(image, image_size)  # Resize to target size\n",
    "            melanoma_images.append(resized_image.flatten())  # Flatten the image\n",
    "            melanoma_labels.append(1)  # Label for melanoma\n",
    "\n",
    "    non_melanoma_images = []\n",
    "    non_melanoma_labels = []\n",
    "\n",
    "    for image_path in non_melanoma_df['path']:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Load as RGB\n",
    "        if image is not None:\n",
    "            resized_image = cv2.resize(image, image_size)  # Resize to target size\n",
    "            non_melanoma_images.append(resized_image.flatten())  # Flatten the image\n",
    "            non_melanoma_labels.append(0)  # Label for non-melanoma\n",
    "\n",
    "    # Combine melanoma and non-melanoma data\n",
    "    X = np.array(melanoma_images + non_melanoma_images)\n",
    "    y = np.array(melanoma_labels + non_melanoma_labels)\n",
    "\n",
    "    # Apply SMOTE-Tomek\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "\n",
    "    synthetic_data = {\"image_name\": [], \"melanoma\": [], \"path\": []}\n",
    "    for i, (image_data, label) in enumerate(zip(X_resampled, y_resampled)):\n",
    "        reshaped_image = image_data.reshape(image_size[0], image_size[1], 3)  # Reshape to original size\n",
    "        output_image_path = os.path.join(output_folder, f\"synthetic_{i}.jpg\")\n",
    "        cv2.imwrite(output_image_path, reshaped_image)  # Save the image\n",
    "        synthetic_data[\"image_name\"].append(f\"synthetic_{i}\")\n",
    "        synthetic_data[\"melanoma\"].append(label)\n",
    "        synthetic_data[\"path\"].append(output_image_path)\n",
    "\n",
    "    # Save the updated DataFrame\n",
    "    synthetic_df = pd.DataFrame(synthetic_data)\n",
    "    synthetic_df.to_csv(output_csv_path, mode='a', header=False)\n",
    "    print(f\"Updated CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97daa4a3",
   "metadata": {},
   "source": [
    "#### View Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_melanoma(data_frame: pd.DataFrame) -> int:\n",
    "    # Count number of melanoma vs non-melanoma\n",
    "    melanoma_count = data_frame[data_frame[\"MEL\"] == 1].shape[0]\n",
    "    non_melanoma_count = data_frame[data_frame[\"MEL\"] == 0].shape[0]\n",
    "\n",
    "    print(f\"\\nMelanoma images: {melanoma_count}\")\n",
    "    print(f\"Non-Melanoma images: {non_melanoma_count}\")\n",
    "\n",
    "    # Percent distribution\n",
    "    print(\"\\nMEL column class distribution (%):\")\n",
    "    print(data_frame[\"MEL\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "def view_images(folder: str, image_files: list[str], num=0) -> None:\n",
    "    \"\"\"\n",
    "    View a subset of images from the dataset.\n",
    "\n",
    "    image_files: List of image file names\n",
    "    num: Number of images to display\n",
    "    \"\"\"\n",
    "    if num == 0:\n",
    "        num = len(image_files)\n",
    "    n_rows = math.ceil(num // 5)\n",
    "    n_cols = 5\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 5))  # Adjust figure size dynamically\n",
    "    for i, image_file in enumerate(image_files[:num]):\n",
    "        image_path = os.path.join(folder, image_file)\n",
    "        img = mpimg.imread(image_path)\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        # Check if the image is grayscale\n",
    "        if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.title(image_file, fontsize=8)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421415b2",
   "metadata": {},
   "source": [
    "#### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_isic = '/Users/audreylu/.cache/kagglehub/datasets/andrewmvd/isic-2019/versions/1'  # Update this path as needed\n",
    "base_path_ham = '/Users/audreylu/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2'  # Update this path as needed\n",
    "image_folder = os.path.join(base_path, 'ISIC_2019_Training_Input', 'ISIC_2019_Training_Input')\n",
    "labels_path = os.path.join(base_path, 'ISIC_2019_Training_GroundTruth.csv')\n",
    "output_folder = '../../preprocessed_dataset'  # Update this path as needed\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "balanced_csv_path = 'ISIC_2019_Training_Balanced.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d3937",
   "metadata": {},
   "source": [
    "#### View Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Check Images ===\n",
    "# List only .jpg image files (ignore folders)\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg') and os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "print(\"Total .jpg files found:\", len(image_files))\n",
    "print(\"Sample image names:\", image_files[:5])\n",
    "\n",
    "# === Visualize First 5 Images ===\n",
    "print(\"\\nImages before preprocessing:\")\n",
    "view_images(image_folder, image_files, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d6ec5",
   "metadata": {},
   "source": [
    "#### Filter All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52faf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Filtering and Preprocessing ===\n",
    "\n",
    "# Testing with first 5 images\n",
    "# filter_all_images(image_folder, output_folder, image_files[:5])\n",
    "\n",
    "filter_all_images(image_folder, output_folder, image_files)\n",
    "print(\"\\nImages after filtering:\")\n",
    "result_files = [f for f in os.listdir(output_folder) if f.endswith('.jpg') and os.path.isfile(os.path.join(output_folder, f))]\n",
    "result_files.sort()\n",
    "view_images(output_folder, result_files, 5)\n",
    "# view_images(output_folder, result_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b9352",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Labels CSV ===\n",
    "df = pd.read_csv(labels_path)[['image', 'MEL']]\n",
    "print(\"\\nTraining labels preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# === Melanoma vs. Non-Melanoma ===\n",
    "num_melanoma(df)  # Display the number of melanoma vs non-melanoma images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e57e87",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38debea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nApplying data augmentation to balance the dataset...\")\n",
    "upsample_melanoma_images(df, image_folder, output_folder, balanced_csv_path)\n",
    "print(f\"Updated CSV saved to {balanced_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986e94d",
   "metadata": {},
   "source": [
    "#### Preview Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe33066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.read_csv(balanced_csv_path)\n",
    "print(\"\\nBalanced dataset preview:\")\n",
    "print(df_balanced.head())\n",
    "num_melanoma(df_balanced)  # Display the number of melanoma vs non-melanoma images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melanoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
