{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  25331\n",
      "Testing data:  8238\n",
      "Training labels:  25331\n",
      "Testing labels:  8238\n"
     ]
    }
   ],
   "source": [
    "training_path = \"../isic_2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
    "testing_path = \"../isic_2019/ISIC_2019_Test_Input/ISIC_2019_Test_Input\"\n",
    "\n",
    "training_labels_path = \"../isic_2019/ISIC_2019_Training_Input/ISIC_2019_Training_GroundTruth.csv\"\n",
    "testing_labels_path = \"../isic_2019/ISIC_2019_Test_Input/ISIC_2019_Test_GroundTruth.csv\"\n",
    "\n",
    "training_labels = pd.read_csv(training_labels_path)\n",
    "testing_labels = pd.read_csv(testing_labels_path)\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    data = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            data.append(filename)\n",
    "    return data\n",
    "\n",
    "training_data = load_data(training_path)\n",
    "print(\"Training data: \", len(training_data))\n",
    "testing_data = load_data(testing_path)\n",
    "print(\"Testing data: \", len(testing_data))\n",
    "\n",
    "print(\"Training labels: \", len(training_labels))\n",
    "print(\"Testing labels: \", len(testing_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels preview:\n",
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "Melanoma images: 4522\n",
      "Non-Melanoma images: 20809\n",
      "MEL\n",
      "0.0    82.148356\n",
      "1.0    17.851644\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify extracted data\n",
    "\n",
    "\n",
    "df = training_labels\n",
    "print(\"Training labels preview:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Peek of MEL column and NON-MEL values\n",
    "melanoma_count = df[df[\"MEL\"] == 1].shape[0]\n",
    "non_melanoma_count = df[df[\"MEL\"] == 0].shape[0]\n",
    "\n",
    "# Printing the counts\n",
    "print(f\"Melanoma images: {melanoma_count}\")\n",
    "print(f\"Non-Melanoma images: {non_melanoma_count}\")\n",
    "\n",
    "# Get overall class distribution\n",
    "print(df[\"MEL\"].value_counts(normalize=True) * 100)  # Shows % distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melanoma images:  4522\n",
      "Melanocytic nevus images:  12875\n",
      "Basal cell carcinoma images:  3323\n",
      "Actinic keratosis images:  867\n",
      "Benign keratosis images:  2624\n",
      "Dermatofibroma images:  239\n",
      "Vascular lesion images:  253\n",
      "Squamous cell carcinoma images:  628\n",
      "None of the above images:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Melanoma images: \", len(df[df[\"MEL\"] == 1]))\n",
    "print(\"Melanocytic nevus images: \", len(df[df[\"NV\"] == 1]))\n",
    "print(\"Basal cell carcinoma images: \", len(df[df[\"BCC\"] == 1]))\n",
    "print(\"Actinic keratosis images: \", len(df[df[\"AK\"] == 1]))\n",
    "print(\"Benign keratosis images: \", len(df[df[\"BKL\"] == 1]))\n",
    "print(\"Dermatofibroma images: \", len(df[df[\"DF\"] == 1]))\n",
    "print(\"Vascular lesion images: \", len(df[df[\"VASC\"] == 1]))\n",
    "print(\"Squamous cell carcinoma images: \", len(df[df[\"SCC\"] == 1]))\n",
    "print(\"None of the above images: \", len(df[df[\"UNK\"] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "To keep a good proportion of the different types of non-melanoma images\n",
    "Apply data augmentation to true melanoma to oversample\n",
    "Apply under sampling to non melanoma set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Mel count:  {'NV': 12875, 'BCC': 3323, 'AK': 867, 'BKL': 2624, 'DF': 239, 'VASC': 253, 'SCC': 628}\n",
      "Total non-mel:  20809\n",
      "Sampling proportions:  {'NV': 0.6187226680763132, 'BCC': 0.15969051852563795, 'AK': 0.04166466432793503, 'BKL': 0.12609928396366957, 'DF': 0.011485414964678744, 'VASC': 0.0121582007785093, 'SCC': 0.030179249363256284}\n",
      "Size:  14517\n",
      "Total non-mel:  9995\n",
      "Total mel:  4522\n",
      "NV 6187\n",
      "BCC 1596\n",
      "AK 416\n",
      "BKL 1260\n",
      "DF 114\n",
      "VASC 121\n",
      "SCC 301\n"
     ]
    }
   ],
   "source": [
    "'''NEW UNDERSAMPLING'''\n",
    "\n",
    "def undersample_data_proportional(df, target_size, new_labels_path):\n",
    "    df = pd.read_csv(training_labels_path)\n",
    "    mel_df = df[df[\"MEL\"] == 1]\n",
    "    non_mel_df = df[df[\"MEL\"] == 0]\n",
    "\n",
    "    non_mel_types = [\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\"]\n",
    "    non_mel_counts = {label: non_mel_df[non_mel_df[label] == 1.0].shape[0] for label in non_mel_types}\n",
    "    print(\"Non Mel count: \", non_mel_counts)\n",
    "    total_non_mel = sum(non_mel_counts.values())\n",
    "    print(\"Total non-mel: \", total_non_mel)\n",
    "\n",
    "    # Calculate sampling proportions\n",
    "    sampling_props = {k: v / total_non_mel for k, v in non_mel_counts.items()}\n",
    "    print(\"Sampling proportions: \", sampling_props)\n",
    "\n",
    "    undersampled_non_mel = []\n",
    "\n",
    "    for label in non_mel_types:\n",
    "        label_df = non_mel_df[non_mel_df[label] == 1.0]\n",
    "        \n",
    "        # Sample proportionally\n",
    "        target_label_count = int(sampling_props[label] * target_size)\n",
    "        sampled_df = label_df.sample(n=target_label_count, random_state=42)\n",
    "        undersampled_non_mel.append(sampled_df)\n",
    "\n",
    "    # Combine all undersampled non-melanoma and melanoma\n",
    "    df_undersampled = pd.concat([mel_df] + undersampled_non_mel)\n",
    "    df_undersampled = df_undersampled.sort_values(by=\"image\").reset_index(drop=True)\n",
    "\n",
    "    # Shuffle the final dataset\n",
    "    #undersampled_df = undersampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(\"Size: \", df_undersampled.shape[0])\n",
    "    print(\"Total non-mel: \", len(df_undersampled[df_undersampled[\"MEL\"] == 0]))\n",
    "    print(\"Total mel: \", len(df_undersampled[df_undersampled[\"MEL\"] == 1]))\n",
    "    for i in non_mel_types:\n",
    "        print(i, len(df_undersampled[df_undersampled[i] == 1]))\n",
    "        \n",
    "    # Save to CSV\n",
    "    df_undersampled.to_csv(new_labels_path, index=False)\n",
    "\n",
    "\n",
    "undersample_data_proportional(training_labels_path, 10000, \"../ISIC_2019_Training_GroundTruth_preprocessed.csv\")\n",
    "\n",
    "# Read the updated csv and get all new file names\n",
    "undersampled_training_labels = \"../ISIC_2019_Training_GroundTruth_preprocessed.csv\"\n",
    "undersampled_training_labels_df = pd.read_csv(undersampled_training_labels)\n",
    "\n",
    "undersampled_filenames = undersampled_training_labels_df[\"image\"].tolist()\n",
    "undersampled_filenames = [filename + \".jpg\" for filename in undersampled_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FILTERING'''\n",
    "# Hair removal\n",
    "def remove_hair(img):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(7,17))\n",
    "    blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "    bhg= cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
    "    ret,mask = cv2.threshold(bhg,10,255,cv2.THRESH_BINARY)\n",
    "    dst = cv2.inpaint(img,mask,7,cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "    \n",
    "# Gray scale\n",
    "def convert_to_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "# Noise reduction\n",
    "def reduce_noise(image):\n",
    "    bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    median = cv2.medianBlur(bilateral, 5)\n",
    "    return median\n",
    "    \n",
    "# Contrast enhancement\n",
    "def enhance_contrast(image):\n",
    "    enhanced_img = (cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))).apply(image)\n",
    "    return enhanced_img\n",
    "\n",
    "# Resizing\n",
    "def resize_img(img, size=(224, 224)):\n",
    "    resized_img = cv2.resize(img, size)\n",
    "    return resized_img\n",
    "\n",
    "# Other filters (need to debug)\n",
    "\n",
    "# Edge detection\n",
    "def segment_lesion(image):\n",
    "        \n",
    "    #https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html \n",
    "    # look at Otsu binarization; very nice\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    return mask\n",
    "\n",
    "def enhance_borders(image):\n",
    "\n",
    "    # https://docs.opencv.org/4.x/d2/d2c/tutorial_sobel_derivatives.html\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    gradient = np.uint8(gradient * 255 / gradient.max())\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(output_path, preprocessed_image)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Preprocessed: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mpreprocess_all_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mundersampled_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../preprocessed_images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m, in \u001b[0;36mpreprocess_all_images\u001b[1;34m(image_list, output_dir)\u001b[0m\n\u001b[0;32m     23\u001b[0m image_name \u001b[38;5;241m=\u001b[39m image_list[image_name]\n\u001b[0;32m     24\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(training_path, image_name)\n\u001b[1;32m---> 25\u001b[0m preprocessed_image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, image_name)\n\u001b[0;32m     27\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(output_path, preprocessed_image)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      6\u001b[0m gray \u001b[38;5;241m=\u001b[39m convert_to_grayscale(image)\n\u001b[1;32m----> 7\u001b[0m hair_remove \u001b[38;5;241m=\u001b[39m \u001b[43mremove_hair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m noise_reduced \u001b[38;5;241m=\u001b[39m reduce_noise(hair_remove)\n\u001b[0;32m     10\u001b[0m contrast \u001b[38;5;241m=\u001b[39m enhance_contrast(noise_reduced)\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mremove_hair\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      6\u001b[0m bhg\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(blackhat,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mBORDER_DEFAULT)\n\u001b[0;32m      7\u001b[0m ret,mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(bhg,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m255\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n\u001b[1;32m----> 8\u001b[0m dst \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minpaint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINPAINT_TELEA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''PREPROCESSING'''\n",
    "import shutil\n",
    "def preprocessing(image):\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gray = convert_to_grayscale(image)\n",
    "    hair_remove = remove_hair(gray)\n",
    "    noise_reduced = reduce_noise(hair_remove)\n",
    "    \n",
    "    contrast = enhance_contrast(noise_reduced)\n",
    "\n",
    "    resized = cv2.resize(contrast, (224,224))\n",
    "    return resized\n",
    "\n",
    "def preprocess_all_images(image_list, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    elif os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for image_name in range(len(image_list)):\n",
    "        image_name = image_list[image_name]\n",
    "        image_path = os.path.join(training_path, image_name)\n",
    "        preprocessed_image = preprocessing(image_path)\n",
    "        output_path = os.path.join(output_dir, image_name)\n",
    "        cv2.imwrite(output_path, preprocessed_image)\n",
    "        \n",
    "    print(\"Total Preprocessed: \", i)\n",
    "\n",
    "preprocess_all_images(undersampled_filenames, \"../preprocessed_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          image  MEL\n",
      "0  ISIC_0000000  0.0\n",
      "1  ISIC_0000002  1.0\n",
      "2  ISIC_0000004  1.0\n",
      "3  ISIC_0000006  0.0\n",
      "4  ISIC_0000011  0.0\n",
      "(14517, 2)\n"
     ]
    }
   ],
   "source": [
    "'''UPDATING LABELS'''\n",
    "\n",
    "def update_labels(labels_path):\n",
    "    df = pd.read_csv(labels_path)\n",
    "    df = df[['image', 'MEL']] # Drop other columns\n",
    "    df.to_csv(labels_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train_labels_updated = update_labels(undersampled_training_labels)\n",
    "print(df_train_labels_updated.head())\n",
    "print(df_train_labels_updated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before : (14517, 2)\n",
      "Size after : (14517, 2)\n"
     ]
    }
   ],
   "source": [
    "'''DATA AUGMENTATION and OVER-SAMPLING'''\n",
    "# Augmentation pipeline\n",
    "def data_augmentation():\n",
    "    transformation = A.Compose([\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.2,\n",
    "            contrast_limit=0.2,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    ])\n",
    "    return transformation\n",
    "\n",
    "def augment_image(image, transformation, num_augmentations):\n",
    "    augmented_images = []\n",
    "    for _ in range(num_augmentations):\n",
    "        augmented = transformation(image=image)[\"image\"]\n",
    "        augmented_images.append(augmented)\n",
    "    return augmented_images\n",
    "\n",
    "def augment_data(input_labels, input_dir, output_dir, new_file_num, num_augmentations):\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Read labels\n",
    "    df = pd.read_csv(input_labels)\n",
    "\n",
    "    # find melanoma images in the training set\n",
    "    all_melanoma = df[df[\"MEL\"] == 1]['image'].tolist()\n",
    "    print(\"Total mel:\", len(all_melanoma))\n",
    "\n",
    "    # Create transformation pipeline\n",
    "    transformation = data_augmentation()\n",
    "\n",
    "    new_label_rows = []\n",
    "    # new_file_num\n",
    "\n",
    "    for image_name in all_melanoma[:]:\n",
    "        image_name = image_name + \".jpg\"\n",
    "        image = os.path.join(input_dir, image_name).replace(\"\\\\\", \"/\")\n",
    "        if image_name.endswith(\".csv\"):\n",
    "            continue\n",
    "        \n",
    "        # Read image\n",
    "        try:\n",
    "            image = cv2.imread(image)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        # Augment image\n",
    "        augmented_images = augment_image(image, transformation, num_augmentations) \n",
    "        for i, aug_img in enumerate(augmented_images):\n",
    "            # Create new image name\n",
    "            new_image_name = f\"ISIC_00{new_file_num}\"\n",
    "            new_file_num += 1\n",
    "\n",
    "            # Track new label row\n",
    "            new_row = {\"image\": new_image_name,\n",
    "                       \"MEL\": 1.0}\n",
    "            new_label_rows.append(new_row)\n",
    "\n",
    "            # Create new file path\n",
    "            new_filepath = os.path.join(output_dir, new_image_name+\".jpg\").replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # Save augmented images\n",
    "            cv2.imwrite(new_filepath, aug_img)\n",
    "\n",
    "            \n",
    "        \n",
    "    print(\"New labels: \", len(new_label_rows))\n",
    "    df = pd.concat([df, pd.DataFrame(new_label_rows)], ignore_index=True)\n",
    "    df.to_csv(input_labels, index=False)\n",
    "        \n",
    "        \n",
    "\n",
    "# Get the newest file number from the original training labels file\n",
    "df = pd.read_csv(training_labels_path)\n",
    "new_file_num = int((df.tail(1)[\"image\"].values[0])[5:]) + 1\n",
    "\n",
    "preprocessed_directory = \"../preprocessed_images\"\n",
    "augmented_directory = \"../augmented_images\"\n",
    "\n",
    "df = pd.read_csv(undersampled_training_labels)\n",
    "print(\"Size before :\", df.shape)\n",
    "\n",
    "augment_data(undersampled_training_labels, preprocessed_directory, preprocessed_directory, new_file_num, num_augmentations=1)\n",
    "\n",
    "df = pd.read_csv(undersampled_training_labels)\n",
    "print(\"Size after :\", df.shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
