{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d465a587",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0bc6b",
   "metadata": {},
   "source": [
    "#### Download ISIC-2019 Testing Data\n",
    "Download the testing data from https://challenge.isic-archive.com/data/#2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce29dc",
   "metadata": {},
   "source": [
    "#### Filter Functions\n",
    "Grayscale, Hair Removal, Noise Reduction, and Contrast Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129638c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all_images(image_folder: str, output_folder: str, image_files: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Apply all filtering functions to a list of image files.\n",
    "    \n",
    "    image_files: List of image file names\n",
    "    \"\"\"\n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            filter_image(image_folder, output_folder, image_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_file}: {e}\")\n",
    "\n",
    "def filter_image(image_folder: str, output_folder: str, image_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Apply all filtering functions to a single image file.\n",
    "    \n",
    "    image_file: Image file name\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_file}\")\n",
    "    else:\n",
    "        image_gr = grayscale(image)\n",
    "        image_hr = hair_removal(image_gr)\n",
    "        image_nr = noise_reduction(image_hr)\n",
    "        image_ce = contrast_enhancement(image_nr)\n",
    "\n",
    "        image_final = image_nr\n",
    "        output_path = os.path.join(output_folder, image_file)\n",
    "        cv2.imwrite(output_path, image_final)\n",
    "\n",
    "def grayscale(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert the image to grayscale.\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def hair_removal(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply hair removal filter to the image using the Dull Razor algorithm.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))  # creates a kernel for morphing\n",
    "    blackhat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)  # apply blackhat filter (highlights dark regions)\n",
    "    bhg = cv2.GaussianBlur(blackhat, (9, 9), cv2.BORDER_REPLICATE)  # smooths image\n",
    "    _, mask = cv2.threshold(bhg, 50, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # creates a binary mask to detect hair-like structure\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    inpainted_image = cv2.inpaint(image_bgr, mask, 4, cv2.INPAINT_TELEA)\n",
    "    # Convert back to grayscale\n",
    "    return cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def noise_reduction(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply noise reduction to the image using Median Filtering and Bilateral Filtering.\"\"\"\n",
    "    image_mf = cv2.medianBlur(image, 5)  # Apply median filter to reduce salt and pepper noise\n",
    "    image_bf = cv2.bilateralFilter(image_mf, d=17, sigmaColor=100, sigmaSpace=100)  # Apply bilateral filter to reduce noise while preserving edges\n",
    "    return image_bf\n",
    "\n",
    "def contrast_enhancement(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply contrast enhancement to the image using Histogram Equalization.\"\"\"\n",
    "    # Check if the image is grayscale\n",
    "    if len(image.shape) == 2:\n",
    "        # Apply Adaptive Histogram Equalization (CLAHE)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(image)\n",
    "    else:\n",
    "        print(\"Error: Image is not grayscale, cannot apply histogram equalization.\")\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2ffed",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions\n",
    "Updating Labeling, Data Augmentation, Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(output_folder: str, transform_func, data_frame: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Augment images with MEL = 1 to create a new balanced dataset.\n",
    "\n",
    "    output_folder (str): Path to the folder where augmented images and the new DataFrame will be saved.\n",
    "    transform_func (Compose): albumentations transformation function.\n",
    "    data_frame (pd.DataFrame): Original DataFrame containing image data.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Create a new DataFrame to store the balanced dataset\n",
    "    balanced_data = []\n",
    "\n",
    "    for _, row in data_frame.iterrows():\n",
    "        image_name = row[\"image\"]\n",
    "        image_path = os.path.join(output_folder, f\"{image_name}.jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Add the original row to the balanced dataset\n",
    "        balanced_data.append(row)\n",
    "\n",
    "        # If MEL == 1, augment the image and save 3 transformed copies\n",
    "        if row[\"MEL\"] == 1:\n",
    "            for i in range(1, 4):  # Create 3 augmented copies\n",
    "                augmented = transform_func(image=image)\n",
    "                transformed_image = augmented[\"image\"]\n",
    "                augmented_name = f\"{image_name}_{i}.jpg\"\n",
    "                augmented_path = os.path.join(output_folder, augmented_name)\n",
    "                cv2.imwrite(augmented_path, transformed_image)\n",
    "\n",
    "                # Add the new row to the balanced dataset\n",
    "                new_row = row.copy()\n",
    "                new_row[\"image\"] = f\"{image_name}_{i}\"  # Update the image name\n",
    "                balanced_data.append(new_row)\n",
    "\n",
    "    # Create a new DataFrame from the balanced data\n",
    "    df_balanced = pd.DataFrame(balanced_data, columns=data_frame.columns)\n",
    "\n",
    "    # Save the balanced DataFrame to the output folder\n",
    "    df_balanced_path = os.path.join(output_folder, \"ISIC_2019_Training_Balanced.csv\")\n",
    "    df_balanced.to_csv(df_balanced_path, index=True)\n",
    "\n",
    "    print(f\"\\nAugmentation and balancing complete. Balanced DataFrame saved to {df_balanced_path}.\")\n",
    "\n",
    "def resize_images(folder: str, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize all jpg images in a folder to the target size.\n",
    "\n",
    "    folder: Path to the folder containing images\n",
    "    target_size: Tuple specifying the target size (width, height)\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            resized_image = cv2.resize(image, target_size)\n",
    "            cv2.imwrite(image_path, resized_image)  # Save the resized image back to the same path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97daa4a3",
   "metadata": {},
   "source": [
    "#### View Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_melanoma(data_frame: pd.DataFrame) -> int:\n",
    "    # Count number of melanoma vs non-melanoma\n",
    "    melanoma_count = data_frame[data_frame[\"MEL\"] == 1].shape[0]\n",
    "    non_melanoma_count = data_frame[data_frame[\"MEL\"] == 0].shape[0]\n",
    "\n",
    "    print(f\"\\nMelanoma images: {melanoma_count}\")\n",
    "    print(f\"Non-Melanoma images: {non_melanoma_count}\")\n",
    "\n",
    "    # Percent distribution\n",
    "    print(\"\\nMEL column class distribution (%):\")\n",
    "    print(data_frame[\"MEL\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "def view_images(folder: str, image_files: list[str], num=0) -> None:\n",
    "    \"\"\"\n",
    "    View a subset of images from the dataset.\n",
    "\n",
    "    image_files: List of image file names\n",
    "    num: Number of images to display\n",
    "    \"\"\"\n",
    "    if num == 0:\n",
    "        num = len(image_files)\n",
    "    n_rows = math.ceil(num // 5)\n",
    "    n_cols = 5\n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 5))  # Adjust figure size dynamically\n",
    "    for i, image_file in enumerate(image_files[:num]):\n",
    "        image_path = os.path.join(folder, image_file)\n",
    "        img = mpimg.imread(image_path)\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        # Check if the image is grayscale\n",
    "        if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.title(image_file, fontsize=8)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421415b2",
   "metadata": {},
   "source": [
    "#### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''  # Update\n",
    "image_folder = os.path.join(base_path, 'ISIC_2019_Test_Input')\n",
    "labels_path = os.path.join(base_path, 'ISIC_2019_Test_GroundTruth.csv')\n",
    "output_folder = 'preprocessed_dataset'  # Update this path as needed\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "balanced_csv_path = os.path.join(output_folder, 'ISIC_2019_Test_Balanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d3937",
   "metadata": {},
   "source": [
    "#### View Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Check Images ===\n",
    "# List only .jpg image files (ignore folders)\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg') and os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "print(\"Total .jpg files found:\", len(image_files))\n",
    "print(\"Sample image names:\", image_files[:5])\n",
    "\n",
    "# === Visualize First 5 Images ===\n",
    "print(\"\\nImages before preprocessing:\")\n",
    "view_images(image_folder, image_files, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d6ec5",
   "metadata": {},
   "source": [
    "#### Filter All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52faf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Filtering and Preprocessing ===\n",
    "\n",
    "# Testing with first 5 images\n",
    "# filter_all_images(image_folder, output_folder, image_files[:5])\n",
    "\n",
    "filter_all_images(image_folder, output_folder, image_files)\n",
    "print(\"\\nImages after filtering:\")\n",
    "result_files = [f for f in os.listdir(output_folder) if f.endswith('.jpg') and os.path.isfile(os.path.join(output_folder, f))]\n",
    "result_files.sort()\n",
    "view_images(output_folder, result_files, 5)\n",
    "# view_images(output_folder, result_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b9352",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Labels CSV ===\n",
    "df = pd.read_csv(labels_path)\n",
    "print(\"\\nTesting labels preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# === Melanoma vs. Non-Melanoma ===\n",
    "num_melanoma(df)  # Display the number of melanoma vs non-melanoma images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e57e87",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38debea",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5), # limit 30 degrees\n",
    "    A.HorizontalFlip(p=0.5), \n",
    "    A.RandomBrightnessContrast(p=0.2)\n",
    "])\n",
    "print(\"\\nApplying data augmentation to balance the dataset...\")\n",
    "augment_data(output_folder, transform, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986e94d",
   "metadata": {},
   "source": [
    "#### Preview Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe33066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.read_csv(balanced_csv_path)\n",
    "df_balanced = df_balanced[['image', 'MEL']]\n",
    "df_balanced.to_csv(balanced_csv_path, index=True)\n",
    "print(f\"Updated CSV saved to {balanced_csv_path}\")\n",
    "\n",
    "print(\"\\nBalanced dataset preview:\")\n",
    "print(df_balanced.head())\n",
    "num_melanoma(df_balanced)  # Display the number of melanoma vs non-melanoma images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f944c",
   "metadata": {},
   "source": [
    "#### Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b064351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images in the output folder to 224x224\n",
    "print(\"\\nResizing images to 224x224...\")\n",
    "resize_images(output_folder)\n",
    "# Check resized images\n",
    "resized_files = [f for f in os.listdir(output_folder) if f.endswith('.jpg') and os.path.isfile(os.path.join(output_folder, f))]\n",
    "resized_files.sort()\n",
    "print(f\"\\nTotal resized images: {len(resized_files)}\")\n",
    "# Visualize first 5 resized images\n",
    "view_images(output_folder, resized_files, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melanoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
